{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns \n",
    "file_path = 'data\\BB_Rates_15min_from_10-2023.xlsx'\n",
    "data = pd.read_excel(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 3\n",
    "EURUSD = data.iloc[start_index:, :2]\n",
    "\n",
    "# Rename the columns\n",
    "EURUSD.columns = ['Dates', 'Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Dates   Close\n",
      "13539  2024-04-17 09:30:00  1.0632\n",
      "13540  2024-04-17 09:45:00  1.0625\n",
      "13541  2024-04-17 10:00:00   1.063\n",
      "13542  2024-04-17 10:15:00  1.0642\n",
      "13543  2024-04-17 10:30:00  1.0647\n"
     ]
    }
   ],
   "source": [
    "print(EURUSD.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = pd.Timedelta(minutes=15)\n",
    "# Convert the 'Dates' column to datetime format\n",
    "EURUSD['Dates'] = pd.to_datetime(EURUSD['Dates'])\n",
    "\n",
    "# Calculate the difference between consecutive dates\n",
    "EURUSD['TimeDiff'] = EURUSD['Dates'].diff()\n",
    "\n",
    "# Identify the sections with consecutive 15-minute intervals\n",
    "EURUSD['IsConsecutive'] = EURUSD['TimeDiff'] == time_interval\n",
    "EURUSD['Block'] = (EURUSD['IsConsecutive'] != EURUSD['IsConsecutive'].shift()).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Dates   Close  Block  TimeFrame\n",
      "4 2023-10-03 23:15:00  1.0466      2          1\n",
      "5 2023-10-03 23:30:00  1.0465      2          2\n",
      "6 2023-10-03 23:45:00  1.0465      2          3\n",
      "7 2023-10-04 00:00:00  1.0468      2          4\n",
      "8 2023-10-04 00:15:00  1.0467      2          5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilsw\\AppData\\Local\\Temp\\ipykernel_4876\\2151116645.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  EURUSD_filtered['TimeFrame'] = EURUSD_filtered.groupby('Block').cumcount() + 1\n"
     ]
    }
   ],
   "source": [
    "# Filter out sections with fewer than 2 days of consecutive 15-minute observations\n",
    "min_consecutive_minutes = 2 * 24 * 60  # 2 days in minutes\n",
    "valid_blocks = EURUSD.groupby('Block').filter(lambda x: len(x) >= min_consecutive_minutes / 15).Block.unique()\n",
    "EURUSD_filtered = EURUSD[EURUSD['Block'].isin(valid_blocks)]\n",
    "\n",
    "# Add the observation timeframe column\n",
    "EURUSD_filtered['TimeFrame'] = EURUSD_filtered.groupby('Block').cumcount() + 1\n",
    "\n",
    "# Drop the 'TimeDiff' and 'IsConsecutive' columns as they are no longer needed\n",
    "EURUSD_filtered = EURUSD_filtered.drop(columns=['TimeDiff', 'IsConsecutive'])\n",
    "\n",
    "# Display the first few rows of the filtered dataset with the new 'Block' and 'TimeFrame' columns\n",
    "print(EURUSD_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_mapping = {old_block: new_block for new_block, old_block in enumerate(EURUSD_filtered['Block'].unique(), 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EURUSD_filtered['Block'] = EURUSD_filtered['Block'].map(block_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Close</th>\n",
       "      <th>Block</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-03 23:15:00</td>\n",
       "      <td>1.0466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-03 23:30:00</td>\n",
       "      <td>1.0465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-03 23:45:00</td>\n",
       "      <td>1.0465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-04 00:00:00</td>\n",
       "      <td>1.0468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-04 00:15:00</td>\n",
       "      <td>1.0467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates   Close  Block\n",
       "0 2023-10-03 23:15:00  1.0466      1\n",
       "1 2023-10-03 23:30:00  1.0465      1\n",
       "2 2023-10-03 23:45:00  1.0465      1\n",
       "3 2023-10-04 00:00:00  1.0468      1\n",
       "4 2023-10-04 00:15:00  1.0467      1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EURUSD_filtered = EURUSD_filtered.reset_index(drop=True)\n",
    "EURUSD_filtered = EURUSD_filtered.drop(columns=['TimeFrame'])\n",
    "EURUSD_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def create_dataset(lookback, forecast_horizon, data):\n",
    "        X, Y = [], []\n",
    "        scaler = MinMaxScaler()\n",
    "        for i in range(len(data) - lookback - forecast_horizon + 1):\n",
    "            if data.iloc[i]['Block'] == data.iloc[i + lookback + forecast_horizon - 1]['Block']:\n",
    "                X_values = data.iloc[i:i+lookback]['Close'].values\n",
    "                Y_values = data.iloc[i+lookback:i+lookback+forecast_horizon]['Close'].values\n",
    "                X_scaled = scaler.fit_transform(X_values.reshape(-1, 1))\n",
    "                Y_scaled = scaler.transform(Y_values.reshape(-1, 1))\n",
    "                X.append(X_scaled)\n",
    "                Y.append(Y_scaled)\n",
    "        return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = create_dataset(lookback=96, forecast_horizon=96, data=EURUSD_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(X, Y)\n",
    "#dataloader = DataLoader(dataset, batch_size=96, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6315\n",
      "1579\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8*len(dataset))\n",
    "test_size = len(dataset)-train_size\n",
    "print(train_size)\n",
    "print(test_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(dataset, test_size=test_size, random_state=42)\n",
    "train_data = torch.tensor(np.array(train_data), dtype=torch.float32)\n",
    "test_data = torch.tensor(np.array(test_data), dtype=torch.float32)\n",
    "\n",
    "test_data = test_data.view(-1,2, 96)\n",
    "train_data = train_data.view(-1, 2, 96)\n",
    "train_data.shape\n",
    "batch_size = 64\n",
    "train_loader  = torch.utils.data.DataLoader(train_data, batch_size= batch_size, shuffle=True)\n",
    "test_loader   = torch.utils.data.DataLoader(test_data, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bi_lstm = nn.LSTM(input_dim, hidden_dim, num_layers, bidirectional=True, batch_first=True)\n",
    "                 \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size)\n",
    "        output, (h_n, c_n) = self.bi_lstm(x)\n",
    "        # h_n: (num_layers, batch_size, hidden_size)\n",
    "        # c_n: (num_layers, batch_size, hidden_size)\n",
    "        return output, h_n, c_n\n",
    "        \n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attn = nn.Linear(self.hidden_dim*2, hidden_dim)  # *2 für bidirektional\n",
    "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, encoder_outputs, hidden):\n",
    "        timestep = encoder_outputs.size(1)\n",
    "        h = hidden[-1].unsqueeze(1).repeat(1, timestep, 1)\n",
    "        attn_energies = self.score(h, encoder_outputs)\n",
    "        return torch.softmax(attn_energies, dim=1)\n",
    "    \n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        energy = torch.tanh(self.attn(torch.cat([hidden, encoder_outputs], dim=2)))\n",
    "        energy = self.v(energy).squeeze(2)\n",
    "        return energy\n",
    "\n",
    "class ProbabilisticDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, num_layers):\n",
    "        super(ProbabilisticDecoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.lstm = nn.LSTM(hidden_dim*2, hidden_dim, num_layers, batch_first=True)  # *2 für bidirektionale Ausgabe\n",
    "        self.fc_mean = nn.Linear(hidden_dim, output_dim)\n",
    "        self.fc_std = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, encoder_outputs, hidden, cell):\n",
    "        attn_weights = self.attention(encoder_outputs, hidden)\n",
    "        context = attn_weights.unsqueeze(1).bmm(encoder_outputs)\n",
    "        \n",
    "        lstm_input = torch.cat([x, context], dim=2)\n",
    "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        \n",
    "        mean = self.fc_mean(output.squeeze(1))\n",
    "        std = torch.exp(self.fc_std(output.squeeze(1)))  # Ensure std is positive\n",
    "        return mean, std, hidden, cell\n",
    "\n",
    "class ProbabilisticSeq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(ProbabilisticSeq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, src, trg, trg_len):\n",
    "        encoder_outputs, hidden, cell = self.encoder(src)\n",
    "        means = torch.zeros(trg.size(0), trg.size(1), self.decoder.output_dim).to(src.device)\n",
    "        stds = torch.zeros(trg.size(0), trg.size(1), self.decoder.output_dim).to(src.device)\n",
    "        \n",
    "\n",
    "        ##hier ist der fehler irgendwo\n",
    "        # Initialisierung des ersten Decodereingangs\n",
    "        print(trg.shape)\n",
    "        input = trg[ 0, :].unsqueeze(1)  # Hier stellen wir sicher, dass die Form (batch_size, 1, 1) ist\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            mean, std, hidden, cell = self.decoder(input, encoder_outputs, hidden, cell)\n",
    "            means[:, t, :] = mean\n",
    "            stds[:, t, :] = std\n",
    "            input = mean.unsqueeze(1)  # Der nächste Decodereingang hat ebenfalls die Form (batch_size, 1, 1)\n",
    "        \n",
    "        return means, stds\n",
    "\n",
    "def negative_log_likelihood(y_true, mean, std):\n",
    "    # Log-Likelihood of a Gaussian\n",
    "    return torch.mean(0.5 * torch.log(2 * np.pi * std**2) + (y_true - mean)**2 / (2 * std**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell initialisieren\n",
    "input_dim = X.size(1)\n",
    "hidden_dim = 100\n",
    "num_layers = 2\n",
    "output_dim = Y.size(1)\n",
    "\n",
    "encoder = Encoder(input_dim, hidden_dim, num_layers)\n",
    "decoder = ProbabilisticDecoder(output_dim, hidden_dim, num_layers)\n",
    "model = ProbabilisticSeq2Seq(encoder, decoder)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 96])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_item = next(iter(train_loader))\n",
    "#print(first_item)\n",
    "first_item[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 96])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m src \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m trg \u001b[38;5;241m=\u001b[39m trg\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 7\u001b[0m means, stds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m negative_log_likelihood(trg, means, stds)\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[86], line 72\u001b[0m, in \u001b[0;36mProbabilisticSeq2Seq.forward\u001b[1;34m(self, src, trg, trg_len)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m##hier ist der fehler irgendwo\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Initialisierung des ersten Decodereingangs\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(trg\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mtrg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Hier stellen wir sicher, dass die Form (batch_size, 1, 1) ist\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, trg_len):\n\u001b[0;32m     75\u001b[0m     mean, std, hidden, cell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\u001b[38;5;28minput\u001b[39m, encoder_outputs, hidden, cell)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    src = batch[:, 0, :, ]\n",
    "    trg = batch[:, 1, :, ]\n",
    "    trg_len = trg.size(1)\n",
    "    src = src.to(device)\n",
    "    trg = trg.to(device)\n",
    "    means, stds = model(src, trg, trg_len)\n",
    "    loss = negative_log_likelihood(trg, means, stds)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
