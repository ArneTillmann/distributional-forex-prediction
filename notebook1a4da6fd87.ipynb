{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T12:31:47.763819Z","iopub.status.busy":"2024-06-23T12:31:47.763548Z","iopub.status.idle":"2024-06-23T12:31:52.821108Z","shell.execute_reply":"2024-06-23T12:31:52.819907Z","shell.execute_reply.started":"2024-06-23T12:31:47.763795Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","from sklearn.preprocessing import MinMaxScaler\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch import nn\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T12:31:52.823487Z","iopub.status.busy":"2024-06-23T12:31:52.822989Z","iopub.status.idle":"2024-06-23T12:31:52.869950Z","shell.execute_reply":"2024-06-23T12:31:52.868960Z","shell.execute_reply.started":"2024-06-23T12:31:52.823454Z"},"trusted":true},"outputs":[],"source":["\n","\n","# Beispiel für Forex-Daten (EUR/USD in 15-Minuten-Intervallen)\n","# Daten sollten als numpy-Array vorliegen: (Anzahl der Beobachtungen, 1)\n","forex_data = np.random.rand(1000, 1)  # Dummy-Daten, ersetzen Sie dies durch Ihre Forex-Daten\n","\n","# Skalierung der Daten\n","scaler = MinMaxScaler()\n","forex_data = scaler.fit_transform(forex_data)\n","\n","# Parameter\n","sequence_length = 96  # 1 Tag in 15-Minuten-Intervallen\n","forecast_horizon = 1  # Vorhersage von 1 Zeitschritt (15 Minuten) in die Zukunft\n","\n","# Funktion zur Erstellung von Eingabesequenzen und Zielwerten\n","def create_sequences(data, seq_length, horizon):\n","    inputs = []\n","    targets = []\n","    for i in range(len(data) - seq_length - horizon + 1):\n","        input_seq = data[i:i + seq_length]\n","        target_seq = data[i + seq_length:i + seq_length + horizon]\n","        inputs.append(input_seq)\n","        targets.append(target_seq)\n","    return np.array(inputs), np.array(targets)\n","\n","# Erstellen der Eingabesequenzen und Zielwerte\n","X, y = create_sequences(forex_data, sequence_length, forecast_horizon)\n","\n","# Umwandlung in PyTorch-Tensoren\n","X = torch.tensor(X, dtype=torch.float32)\n","y = torch.tensor(y, dtype=torch.float32)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T12:31:52.877108Z","iopub.status.busy":"2024-06-23T12:31:52.874526Z","iopub.status.idle":"2024-06-23T12:31:52.902795Z","shell.execute_reply":"2024-06-23T12:31:52.901688Z","shell.execute_reply.started":"2024-06-23T12:31:52.877058Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train size: 632\n","Validation size: 135\n","Test size: 137\n"]}],"source":["\n","# Aufteilung in Trainings-, Validierungs- und Testdatensätze\n","train_size = int(0.7 * len(X))\n","val_size = int(0.15 * len(X))\n","test_size = len(X) - train_size - val_size\n","\n","X_train, y_train = X[:train_size], y[:train_size]\n","X_val, y_val = X[train_size:train_size + val_size], y[train_size:train_size + val_size]\n","X_test, y_test = X[train_size + val_size:], y[train_size + val_size:]\n","\n","# Dataset und DataLoader für PyTorch\n","train_dataset = TensorDataset(X_train, y_train)\n","val_dataset = TensorDataset(X_val, y_val)\n","test_dataset = TensorDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","print(f\"Train size: {len(train_loader.dataset)}\")\n","print(f\"Validation size: {len(val_loader.dataset)}\")\n","print(f\"Test size: {len(test_loader.dataset)}\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T12:31:52.906692Z","iopub.status.busy":"2024-06-23T12:31:52.906182Z","iopub.status.idle":"2024-06-23T12:31:52.913670Z","shell.execute_reply":"2024-06-23T12:31:52.912622Z","shell.execute_reply.started":"2024-06-23T12:31:52.906653Z"},"trusted":true},"outputs":[],"source":["\n","# Hyperparameter\n","input_size = 1  # Dimension der Forex-Daten\n","hidden_size = 64  # Dimension des versteckten Zustands\n","latent_space_dim = 32  # Dimension des latenten Raums\n","num_layers = 3  # Anzahl der BiLSTM-Schichten\n","k = 3  # Zeitverzögerungslänge\n","d = 2  # Ordnung der nichtlinearen Merkmale\n","sequence_length = 96  # Länge der Eingabesequenz (1 Tag bei 15-Minuten-Abständen)\n","batch_size = 16\n","num_epochs = 1\n","learning_rate = 1e-3\n"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T14:37:29.291118Z","iopub.status.busy":"2024-06-23T14:37:29.290761Z","iopub.status.idle":"2024-06-23T14:37:29.300663Z","shell.execute_reply":"2024-06-23T14:37:29.299573Z","shell.execute_reply.started":"2024-06-23T14:37:29.291089Z"},"trusted":true},"outputs":[],"source":["class VARModule(nn.Module):\n","    def __init__(self, input_size, k, d):\n","        super(VARModule, self).__init__()\n","        self.k = k\n","        self.d = d\n","        self.linear_transform = nn.Linear(input_size * k, input_size * k)\n","        self.nonlinear_transform = nn.Linear(input_size * (d * (d + 1)) // 2, input_size * d)\n","\n","    def forward(self, x):\n","        batch_size, seq_len, input_size = x.size()\n","        linear_features = []\n","        nonlinear_features = []\n","\n","        for t in range(self.k, seq_len):\n","            linear_feature = x[:, t-self.k:t, :].reshape(batch_size, -1)\n","            linear_features.append(self.linear_transform(linear_feature))\n","\n","            nonlinear_feature = torch.cat([torch.mul(x[:, t-i, :], x[:, t-j, :])\n","                                           for i in range(1, self.d + 1)\n","                                           for j in range(i, self.d + 1)], dim=-1)\n","            nonlinear_features.append(self.nonlinear_transform(nonlinear_feature))\n","\n","        linear_features = torch.stack(linear_features, dim=1)\n","        nonlinear_features = torch.stack(nonlinear_features, dim=1)\n","        return linear_features, nonlinear_features\n"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T14:37:27.842370Z","iopub.status.busy":"2024-06-23T14:37:27.842004Z","iopub.status.idle":"2024-06-23T14:37:27.850057Z","shell.execute_reply":"2024-06-23T14:37:27.849120Z","shell.execute_reply.started":"2024-06-23T14:37:27.842341Z"},"trusted":true},"outputs":[],"source":["class BiLSTMModule(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, dropout=0.2):\n","        super(BiLSTMModule, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        \n","        self.bilstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, \n","                              batch_first=True, bidirectional=True, dropout=dropout)\n","       \n","\n","    def forward(self, x, h_c=None):\n","        if h_c == None:\n","            h_c = (torch.zeros(self.num_layers, x.size(0), self.hidden_size),torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(x.device)\n","        \n","        self.bilstm.flatten_parameters()\n","        out, h_c = self.bilstm(x, h_c)\n","        self.hidden_size = h_c\n","        return out, h_c"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T14:37:25.252018Z","iopub.status.busy":"2024-06-23T14:37:25.251325Z","iopub.status.idle":"2024-06-23T14:37:25.260404Z","shell.execute_reply":"2024-06-23T14:37:25.259351Z","shell.execute_reply.started":"2024-06-23T14:37:25.251989Z"},"trusted":true},"outputs":[],"source":["class DAFA_Modell(nn.Module):\n","    def __init__(self, input_size, hidden_size, latent_space_dim, num_layers, k, d):\n","        super(DAFA_BiLSTM, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.latent_space_dim = latent_space_dim\n","        self.num_layers = num_layers\n","        self.k = k\n","        self.d = d\n","        \n","        self.var_module = VARModule(input_size, k, d)\n","        self.bilstm_layers = nn.ModuleList([BiLSTMModule(self.input_size + self.input_size * k, self.hidden_size, 1) for _ in range(num_layers)])\n","        self.fc = nn.Linear(hidden_size * 2, input_size)  # Bidirectional LSTM doubles the hidden size\n","        \n","    def forward(self, x):\n","        linear_features, nonlinear_features = self.var_module(x)\n","        out = nonlinear_features\n","        for i in range(self.num_layers):\n","            out, _ = self.bilstm_layers[i](torch.cat([out, linear_features], dim=-1))\n","        out = self.fc(out)\n","        return out\n","        \n","      "]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T14:37:58.977807Z","iopub.status.busy":"2024-06-23T14:37:58.976991Z","iopub.status.idle":"2024-06-23T14:37:58.981882Z","shell.execute_reply":"2024-06-23T14:37:58.980888Z","shell.execute_reply.started":"2024-06-23T14:37:58.977779Z"},"trusted":true},"outputs":[],"source":["def loss_function(recon_x, x):\n","    return nn.MSELoss()(recon_x, x)"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T14:38:50.489406Z","iopub.status.busy":"2024-06-23T14:38:50.488733Z","iopub.status.idle":"2024-06-23T14:38:50.494340Z","shell.execute_reply":"2024-06-23T14:38:50.493386Z","shell.execute_reply.started":"2024-06-23T14:38:50.489378Z"},"trusted":true},"outputs":[],"source":["\n","# Hyperparameter\n","input_size = 1  # Dimension der Forex-Daten\n","hidden_size = 64  # Dimension des versteckten Zustands\n","latent_space_dim = 32  # Dimension des latenten Raums\n","num_layers = 3  # Anzahl der BiLSTM-Schichten\n","k = 3  # Zeitverzögerungslänge\n","d = 2  # Ordnung der nichtlinearen Merkmale\n","sequence_length = 96  # Länge der Eingabesequenz (1 Tag bei 15-Minuten-Abständen)\n","batch_size = 16\n","num_epochs = 1\n","learning_rate = 1e-3\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_model(model, train_loader, criterion, optimizer, num_epochs):\n","    model.train()  # Set model to training mode\n","    \n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        \n","        for inputs, targets in train_loader:\n","            optimizer.zero_grad()  # Zero the parameter gradients\n","            \n","            # Forward pass\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            \n","            # Backward and optimize\n","            loss.backward()\n","            optimizer.step()\n","            \n","            running_loss += loss.item() * inputs.size(0)\n","        \n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n","    \n","    print('Training complete')"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T14:42:43.557369Z","iopub.status.busy":"2024-06-23T14:42:43.556755Z","iopub.status.idle":"2024-06-23T14:42:43.567732Z","shell.execute_reply":"2024-06-23T14:42:43.566819Z","shell.execute_reply.started":"2024-06-23T14:42:43.557341Z"},"trusted":true},"outputs":[],"source":["\n","# Initialisierung des Modells, Optimierers und der Loss-Funktion\n","model = DAFA_BiLSTM(input_size, hidden_size, latent_space_dim, num_layers, k, d)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
